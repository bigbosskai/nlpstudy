# 细粒度情感分析
1. Attention-based LSTM for Aspect-level Sentiment Classification(emnlp2016)
2. Effective LSTMs for Target-Dependent Sentiment Classfifcation(COLING 2016)
3. Recurrent Attention Network on Memory for Aspect Sentiment Analysis(emnlp2017)
4. Learning to Attend via Word-Aspect Associative Fusion for Aspect-Based Sentiment Analysis
5. IARM: Inter-Aspect Relation Modeling with Memory Networks in Aspect-Based Sentiment Analysis(emnlp2018
6. An Interactive Multi-Task Learning Network for End-to-End Aspect-Based Sentiment Analysis(acl2019)
7. Semantic Compositionality through Recursive Matrix-Vector Spaces
8. Hierarchical Attention Based Position-aware Network for Aspect-level Sentiment Analysis(CoNLL2018)
9. Parameterized Convolutional Neural Networks for Aspect Level Sentiment Classification(emnlp2018)
10. Self-Attention: A Better Building Block for Sentiment Analysis Neural Network Classifiers(acl2018)
11. Progressive Self-Supervised Attention Learning for Aspect-Level Sentiment Analysis(acl2019)
12. Adaptive Recursice Neural Network for Target-dependent Twitter Sentiment Classification(acl2014)
13. Aspect Level Sentiment Classification with Deep Memory Network(emnlp2016)
14. Interactive Attention Networks for Aspect-Level Sentiment Classfification(ijcai2017)
15. Aspect Based Sentiment Analysis with Gated Convolutional Networks(acl2018)
16. Refining Word Embeddings for Sentiment Analysis(emnlp2017)
17. Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks
# 句法分析
1. Viable Dependency Parsing as Sequence Labeling(naacl2019)
2. Sequence Labeling Parsing by Learning Across Representation(acl2019)
3. Efficient Third-order Dependency Parsers(acl2010)
4. Dependency-Based Word Embeddings(acl2014)
5. Joint Optimization for Chinese POS Tagging and Dependency Parsing( IEEE/ACM TRANSACTIONS ON AUDIO, SPEECH, AND LANGUAGE PROCESSING 2014)
6. Online Learning of Approximate Dependency Parsing Algorithms
7. Online Large-Margin Training of Dependency Parsers
8. Efficient Second-Order TreeCRF for Neural Dependency Parsing
9. Neural Joint Model for Transition-based Chinese Syntactic Analysis
10. A Graph-based Model for Joint Chinese Word Segmentation and Dependency Parsing
11. Graph-based Dependency Parsing with Bidirectional LSTM
12. Second-Order Semantic Dependency Parsing with End-to-End Neural Networks(2019acl)
13. DEEP BIAFFINE ATTENTION FOR NEURAL DEPENDENCY PARSING(ICLR2017)
14. A Fast and Accurate Dependency Parser using Neural Networks
15. A Top-down Model for Character-level Chinese Dependency Parsing
16. Adaptation of Multilingual Transformer Encoder forRobust Enhanced Universal Dependency Parsing(acl2020)
17. Stack-Pointer Networks for Dependency Parsing
18. Graph-based Dependency Parsing with Graph Neural Networks
19. Self-attentive Biaffine Dependency Parsing
29. A Simple and Effective Dependency parser for Telugu
30. 基于多特征融合编码的神经网络依存句法分析模型
`名童师兄转移句法发的中文信息学报`
# 如何使用句法
1. Joint Chinese Word Segmentation and Part-of-speech Tagging via Two-way Attentions of Auto-analyzed Knowledge(acl2020)
2. Syntax-Aware Aspect Level Sentiment Classification with Graph Attention Networks
# 句子匹配（复述识别，自然语言推理，QA)
1. Original Semantics-Oriented Attention and Deep Fusion Network for Sentence Matching(emnlp2019)
2. Neural Graph Matching Networks for Chinese Short Text Matching
3. Syntax-Aware Attention for Natural Language Inference with Phrase-Level Matching
4. Natural Language Inference by Tree-Based Convolution and Heuristic Matching

# 其他
1. Attention Is All You Need
2. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
3. FLAT: Chinese NER Using Flat-Lattice Transformer(acl2020)
4. Design Challenges and Misconceptions in Neural Sequence Labeling
5. Attentive Pooling with Learnable Norms for Text Representation
6. Neural Architectures for Named Entity Recognition
7. State-of-the-art Chinese Word Segmentation with Bi-LSTMs
8. Convolutional Neural Networks for Sentence Classification
9. Attention-Based Bidirectional Long Short-Term Memory Networks for Relation Classification
10. Effective Approaches to Attention-based Neural Machine Translation
11. A Study of Reinforcement Learning for Neural Machine Translation
12. Neural Machine Translation by Jointly Learning to Align and Translate
13. 2019emnlpText Level Graph Neural Network for Text Classification
14. Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics
15. Design Challenges and Misconceptions in Neural Sequence Labeling
16. Attentive Pooling with Learnable Norms for Text Representation
17. Gradient Normalization for Adaptive  Loss Balancing in Deep Multitask Networks
18. State-of-the-art Chinese Word Segmentation with Bi-LSTMs
